{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70dae23e-c7f5-4570-a6fc-ecb7195a6eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLEARML_WEB_HOST=https://app.5ccsagap.er.kcl.ac.uk/\n",
      "env: CLEARML_API_HOST=https://api.5ccsagap.er.kcl.ac.uk\n",
      "env: CLEARML_FILES_HOST=https://files.5ccsagap.er.kcl.ac.uk\n",
      "env: CLEARML_API_ACCESS_KEY=OYY8NIAZE2KGIB30TKDSDGGLCFQSBD\n",
      "env: CLEARML_API_SECRET_KEY=0V65RLv6rElVM8eDRzyZLuM2jkwfOHYrqj-dIejcbFyKe-PtTcheGID6tGRU2C59vPw\n"
     ]
    }
   ],
   "source": [
    "%env CLEARML_WEB_HOST=https://app.5ccsagap.er.kcl.ac.uk/\n",
    "%env CLEARML_API_HOST=https://api.5ccsagap.er.kcl.ac.uk\n",
    "%env CLEARML_FILES_HOST=https://files.5ccsagap.er.kcl.ac.uk\n",
    "%env CLEARML_API_ACCESS_KEY=OYY8NIAZE2KGIB30TKDSDGGLCFQSBD\n",
    "%env CLEARML_API_SECRET_KEY=0V65RLv6rElVM8eDRzyZLuM2jkwfOHYrqj-dIejcbFyKe-PtTcheGID6tGRU2C59vPw\n",
    "\n",
    "seed = 8012004\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, PowerTransformer\n",
    "from scipy.stats import zscore, mstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97bdf88c-9a4b-4eab-8ec8-a25541e91479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=cb3636b8c04a4c31ac7cb6ee399b2119\n",
      "ClearML results page: https://app.5ccsagap.er.kcl.ac.uk/projects/f78baf0a8c954173b8cae46e34eb26b6/experiments/cb3636b8c04a4c31ac7cb6ee399b2119/output/log\n",
      "2025-02-20 09:35:28,330 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "CLEARML-SERVER new package available: UPGRADE to v2.0.0 is recommended!\n",
      "Release Notes:\n",
      "### Breaking Changes\n",
      "\n",
      "MongoDB major version was upgraded from v5.x to 6.x.\n",
      "Please note that if your current ClearML Server version is smaller than v1.17 (where MongoDB v5.x was first used), you'll need to first upgrade to ClearML Server v1.17.\n",
      "#### Upgrading to ClearML Server v1.17 from a previous version\n",
      "- If using docker-compose,  use the following docker-compose files:\n",
      "  * [docker-compose file](https://github.com/allegroai/clearml-server/blob/2976ce69cc91550a3614996e8a8d8cd799af2efd/upgrade/1_17_to_2_0/docker-compose.yml)\n",
      "  * [docker-compose file foe Windows](https://github.com/allegroai/clearml-server/blob/2976ce69cc91550a3614996e8a8d8cd799af2efd/upgrade/1_17_to_2_0/docker-compose-win10.yml)\n",
      "\n",
      "### New Features\n",
      "\n",
      "- New look and feel: Full light/dark themes ([clearml #1297](https://github.com/allegroai/clearml/issues/1297))\n",
      "- New UI task creation options\n",
      "  - Support bash as well as python scripts\n",
      "  - Support file upload\n",
      "- New UI setting for configuring cloud storage credentials with which ClearML can clean up cloud storage artifacts on task deletion. \n",
      "- Add UI scalar plots presentation of plots in sections grouped by metrics.\n",
      "- Add UI Batch export plot embed codes for all metric plots in a single click.\n",
      "- Add UI pipeline presentation of steps grouped into stages\n",
      "\n",
      "### Bug Fixes\n",
      "- Fix UI Model Endpoint's Number of Requests plot sometimes displays incorrect data\n",
      "- Fix UI datasets page does not filter according to project when dataset is running \n",
      "- Fix UI task scalar legend does not change colors when smoothing is enabled \n",
      "- Fix queue list in UI Workers and Queues page does not alphabetically sort by queue display name \n",
      "- Fix queue display name is not searchable in UI Task Creation modal's queue field\n",
      "\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "2025-02-20 09:35:33,058 - clearml.Task - INFO - Completed model upload to https://files.5ccsagap.er.kcl.ac.uk/CW1_Project/RandomForest_SubM.cb3636b8c04a4c31ac7cb6ee399b2119/models/19210-4779509904-dd809663dd5745c7a1da14b1f0364ed4.pkl\n",
      "Best Hyperparameters: {'n_estimators': 700, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_samples': 0.7, 'max_features': None, 'max_depth': 40, 'ccp_alpha': 0.005, 'bootstrap': True}\n",
      "Test Set R²: 0.4718\n",
      "Test Set MAE: 7.4000\n",
      "Submission file 'CW1_submission.csv' generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import ClearML\n",
    "from clearml import Task\n",
    "\n",
    "# Initialize ClearML task (experiment tracking)\n",
    "task = Task.init(project_name=\"CW1_Project\", task_name=\"RandomForest_SubM\", output_uri=True)\n",
    "\n",
    "#Data Cleaning and Feature Engineering\n",
    "def clean_and_engineer(df):\n",
    "    # Feature engineering: Volume, Surface Area, Aspect Ratios\n",
    "    df['volume'] = df['x'] * df['y'] * df['z']\n",
    "    df['surface_area'] = 2 * (df['x'] * df['y'] + df['x'] * df['z'] + df['y'] * df['z'])\n",
    "    df['aspect_ratio_xy'] = df['x'] / (df['y'] + 1e-6)\n",
    "    df['aspect_ratio_xz'] = df['x'] / (df['z'] + 1e-6)\n",
    "    df['aspect_ratio_yz'] = df['y'] / (df['z'] + 1e-6)\n",
    "\n",
    "    # Winsorize Outliers (1% & 99% percentiles)\n",
    "    for col in ['price', 'x', 'y', 'z', 'volume', 'surface_area']:\n",
    "        if col in df.columns:\n",
    "            df[col] = mstats.winsorize(df[col], limits=[0.01, 0.01])\n",
    "\n",
    "    # Label Encoding for Categorical Variables\n",
    "    for col in ['cut', 'color', 'clarity']:\n",
    "        if col in df.columns:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "\n",
    "    # Drop original dimension features\n",
    "    df.drop(columns=['x', 'y', 'z'], errors='ignore', inplace=True)\n",
    "\n",
    "    # Handle Missing Values\n",
    "    df.fillna(df.median(), inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load dataset and apply cleaning\n",
    "train_df = pd.read_csv(\"data/CW1_train.csv\")\n",
    "train_df = clean_and_engineer(train_df)\n",
    "\n",
    "X = train_df.drop(columns=['outcome'])\n",
    "y = train_df['outcome']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "#Feature Selection (Feature Importance from Baseline Model)\n",
    "baseline_model = RandomForestRegressor(n_estimators=100, random_state=seed, n_jobs=-1)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance and select top features\n",
    "importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': baseline_model.feature_importances_})\n",
    "important_features = importance_df[importance_df['Importance'] > 0.01]['Feature'].tolist()\n",
    "\n",
    "# Keep only important features\n",
    "X = X[important_features]\n",
    "\n",
    "#Standardize Features After Feature Selection\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# RandomizedSearchCV for Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 500, 700],\n",
    "    'max_depth': [20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [4, 6, 8],\n",
    "    'max_features': ['sqrt', None],\n",
    "    'bootstrap': [True],\n",
    "    'ccp_alpha': [0.001, 0.005, 0.01],\n",
    "    'max_samples': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=seed, n_jobs=-1),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,               # Limit to 30 iterations for efficiency\n",
    "    cv=3,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    random_state=seed,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "#Evaluate Model Performance\n",
    "best_params = random_search.best_params_\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Performance Metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Display Results\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Test Set R²: {r2:.4f}\")\n",
    "print(f\"Test Set MAE: {mae:.4f}\")\n",
    "\n",
    "#Generate Submission CSV\n",
    "test_df = pd.read_csv(\"data/CW1_test.csv\")\n",
    "test_df = clean_and_engineer(test_df)\n",
    "\n",
    "# Ensure test features match training feature order\n",
    "X_submission = test_df[important_features]\n",
    "\n",
    "# Standardize test set using the same scaler\n",
    "X_submission = pd.DataFrame(scaler.transform(X_submission), columns=important_features)\n",
    "\n",
    "# Generate predictions\n",
    "yhat = best_model.predict(X_submission)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({'yhat': yhat})\n",
    "submission.to_csv('CW1_submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file 'CW1_submission.csv' generated successfully!\")\n",
    "# Close ClearML task\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T08:07:41.911528Z",
     "start_time": "2025-02-20T08:07:41.910482Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c3137b893354c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
